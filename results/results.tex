\chapter{Experimental Results}

This chapter presents the results from the different experiments held on different dataset configurations using different model arrangements. For general purpose, only the validation accuracy is presented.


The results presented below are done using a fine-tuned version of the VGG-Face. Fine-tuning consists of taking a pre-trained network on a large dataset. This network captures general features that describe a face like curves and edges. This can be done since the SASE-FE dataset consists also on faces. The fine-tuning will allow the new model to
learn features that describe the facial expressions of different emotions. 

%%%%%%%%%%%%%%%%%%%
% SECTION: EMOTION
%%%%%%%%%%%%%%%%%%%
\section{Emotion Results}

The first set of experiments were conducted only to classify the six emotions, both real and fake emotions were combined. These experiments consist of doing fine-tuning to the model using the SASE-FE dataset. The purpose is to explore different configurations and choose the model with the highest test accuracy.

% SUBSECTION: No Pre-processing
\subsection{No Pre-Processing}
The experiments try to explore if adding \textbf{three fully connected layers and/or pooling layer} at the end of the convolutional layers improves the performance of the CNN. Other experiments consist of \textbf{freezing all the convolutional layers, freezing just the first few layers and no freezing any layer}.

\input{tables/fake-emotion_nopre}

After running several configurations, the best configuration is \textbf{all Convolutional layers freezed with three Fully Connected layers and Max Pooling layer at the end} with a test accuracy of \textbf{0.4375}. The following experiments will only use this configuration.

% SUBSECTION: Frontalization
\subsection{Frontalization}
After obtaining the best architecture from the previous experiments, the next experiment is to use the frontalization pre-processed dataset. The experiments show both soft symmetry and no symmetry.

\input{tables/fake-emotion_frontal}

As seen from the previous table, the gap between no symmetry and soft symmetry is huge. The difference is almost \textbf{15\%}.

As discussed on \cite{Hassner2015EffectiveImages}, Hassner et al discussed that in some cases soft symmetry "may actually be unnecessary and possibly even counterproductive; damaging rather than improving face recognition performance". Soft Symmetry uses the detected facial features and modifies the surface to make the blending. However, this blending is an approximation that can result in noise. Specifically, looking at the accuracies, it seems that the detection of emotions is affected greatly by performing soft symmetry. As a conclusion, the next experiment will use no symmetry only.

% SUBSECTION: Fuse Streams
\subsection{Fuse Streams}
According to the analysis from the previous section, no symmetry gives a higher accuracy. Nonetheless, it is interesting to see if combining no symmetry dataset with just the extracted face can help even improve the accuracy. The next experiments consists of using a two-stream CNN, meaning combining a CNN with the no symmetry dataset as input and another CNN with the no pre-processing dataset. To do so, both CNN are fused before the fully connected layers. After the fusing layer, the architecture remains the same.

\input{tables/fake-emotion_fuse}

The two-stream CNN got a test accuracy of \textbf{0.5832}, which is lower than the No Symmetry CNN of \textbf{0.5949}. 

EXPLAIN MORE...

%%%%%%%%%%%%%%%%%%%
% SECTION FAKE VS REAL
%%%%%%%%%%%%%%%%%%%
\section{Fake vs Real Emotion Results}

In this set of experiments, the dataset was split into fake and real emotions, this gives a total of 12 classes. Each of the 6 emotions has a pair of classes, fake and real. The test accuracy are expected to be much lower since there are 12 classes now. The next experiments follow the same order as with the previous section.

% SUBSECTION: Frontalization
\subsection{Face Frontalization}

For sake comparison, both frontalization pre-processed and face dataset test accuracy are shown in table \ref{table:fake-fakereal_frontal}. Both test accuracies are largely similar. This experiment shows the great difficulty that classifying real and fake is. As a conclusion, it can be seen that it is necessary more elaborated methods such as multi-modal architectures.

\input{tables/fake-fakereal_frontal}

% SUBSECTION: Fuse Streams
\subsection{Fuse Two-Streams}
In the previous section, one CNN was used to train two different datasets, frontalization dataset and face frontalization. This experiment now uses a fuse two-stream CNN that combines both datasets.

\input{tables/fake-fakereal_fuse}

The combined CNN gets a huge improved in accuracy from one CNN. The increment consists of almost \textbf{4\%} decimal points.

% SUBSECTION: Frontalization and Geometry
\subsection{Fuse Frontalization and Geometry}
This set of experiments uses one CNN with the frontalization dataset as an input plus the geometry dataset concatenated after the convolutional layers.

\input{tables/fake-fakereal_frontal_geo}

The test accuracy reported of \textbf{0.2994} does increase with adding the geometry from the base accuracy. However, adding the geometry does not outperform the the two-stream accuracy of \textbf{0.3206}.

%%%%%%%%%%%%%%%%%%%
% SECTION BLOCKED VS REAL
%%%%%%%%%%%%%%%%%%%
\section{Blocked vs Real Emotion}

BLOCKED VS REAL